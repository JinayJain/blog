<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <meta property="og:title" content="Telling the Time with Computer Vision - Jinay Jain" />
    <meta property="og:description" content="Overengineering an approach to reading an analog clock" />

    <meta name="twitter:title" content="Telling the Time with Computer Vision - Jinay Jain" />
    <meta name="twitter:description" content="Overengineering an approach to reading an analog clock" />
    <meta name="twitter:card" content="summary" />

    <link rel="shortcut icon" href="/images/favicon.png" type="image/x-icon">
    <link rel="stylesheet" href="../../styles/post.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.0/styles/an-old-hope.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css">
    <title>Telling the Time with Computer Vision</title>
</head>

<body>
    <div class="content">
        <div class="header">

            <div class="title-bar">
                <div class="links">

                    <h3><a href="https://jinay.dev/">home</a></h3>
                    <h3><a href="/">blog</a></h3>
                </div>
                <h1 class="title">Telling the Time with Computer Vision</h1>
            </div>
            <p class="description">Overengineering an approach to reading an analog clock</p>
            <h3 class="author">Jinay Jain<span class="date"> - Nov 18, 2021</span></h3>
        </div>
        <p>Few things are more embarrassing than having to spend 20 seconds trying to figure out how much time you have left on a standardized test. With no phone, smartwatch, or digital clock handy, you’re stuck trying to remember how to decipher the three lines on a circular wall clock. Unfortunately for many people (including me) who grew up surrounded by digital devices, the analog clock has not fully been phased out in the real world.</p>
<p>Now, any normal person would revise their hour and minute hands to brush up on these skills, but you’re not going to be one of those people. You’re going to be a computer vision expert. You’re going to throw everything you know about vision algorithms at this simple task. And that’s exactly what I did.</p>
<h1>Building the Timekeeper</h1>
<p>For those who want to follow along, here’s the code I used to build what I have decided to call the <a href="https://github.com/JinayJain/timekeeper" target="_blank">Timekeeper</a>.</p>
<h2>Where is that clock?</h2>
<p>Before I could even start to code the time-telling aspect of the project, I had to first identify where the clock was in an image. Initially, I tried looking into circle detection algorithms like <a href="https://en.wikipedia.org/wiki/Circle_Hough_Transform" target="_blank">Hough Circles</a>, but that path introduced two problems:</p>
<ol>
<li>Clocks are not the only circular objects in the image.</li>
<li>Due to perspective distortion, the clock’s shape is not always circular.</li>
</ol>
<p>Take a look at the image below. Since the photo was not taken directly facing the clock, its circular shape is distorted into an ellipse. Additionally, the embellishments around the clock could introduce many false-positive circles for a circle detection algorithm.</p>
<p><img src="/images/clock1.png" alt="example of tricky clock"></p>
<p class="caption">A challenging scenario for circle detectors (Photo by Nolwenn Coene from Pexels)</p>
<p>A hand-crafted solution to these issues would likely yield better results, but I decided to go with a more 2021 approach to the issue—deep learning. To my surprise, clocks are actually one of the target labels in the widely used <a href="https://cocodataset.org/" target="_blank">COCO dataset</a>, which is a large, open-source dataset of images of “Common Objects in Context” (COCO). Given the dataset’s ubiquity, I was able to easily find pretrained models that I could use to detect clocks in the image.</p>
<p>However, this dataset seemed to primarily cover what is called the “object segmentation” task, which is where each pixel in the object is labelled as that object (see the example below).</p>
<p><img src="/images/segmentation.png" alt="example of object segmentation"></p>
<p class="caption">An example of object segmentation labels from COCO</p>
<p>For my purposes, I only needed a simple bounding box around the clock, so I searched for a bounding box model that had been trained on COCO. The <a href="https://pytorch.org/vision/stable/index.html" target="_blank">torchvision</a> package has several models that can do object detection, but what I ultimately ended up choosing was the <a href="https://arxiv.org/abs/1506.01497" target="_blank">Faster R-CNN</a> with a <a href="https://arxiv.org/abs/1512.03385" target="_blank">ResNet50</a> backbone. Both of these choices are pretty standard for object detection, and torchvision had a simple API to use them. All in all, the code for finding clock bounding boxes with the Faster R-CNN model was laughably simple:</p>
<p><a href="https://github.com/JinayJain/timekeeper/blob/master/detection.py" target="_blank"><code>detection.py</code></a></p>
<pre class="hljs"><code>model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=<span class="hljs-literal">True</span>)
...
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">detect_clock</span>(<span class="hljs-params">image</span>):</span>
    <span class="hljs-string">&#x27;&#x27;&#x27;Detects a clock within a given image and returns the bounding box&#x27;&#x27;&#x27;</span>


    inp = [torch.from_numpy(preprocess(image)).<span class="hljs-built_in">float</span>().to(device)]
    preds = model(inp)[<span class="hljs-number">0</span>]

    boxes = preds[<span class="hljs-string">&#x27;boxes&#x27;</span>].detach()
    labels = preds[<span class="hljs-string">&#x27;labels&#x27;</span>]
    scores = preds[<span class="hljs-string">&#x27;scores&#x27;</span>]

    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(labels)):
        label = labels[i].item()

        <span class="hljs-keyword">if</span> label == <span class="hljs-number">85</span>: <span class="hljs-comment"># the COCO id for clocks is 85</span>
            <span class="hljs-keyword">return</span> boxes[i].cpu().numpy().<span class="hljs-built_in">round</span>().astype(np.uint16)

    <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span> <span class="hljs-comment"># no clock was found</span>
</code></pre>
<p>I won’t cover the details of object detection here, but you can check out <a href="https://lilianweng.github.io/lil-log/2017/12/31/object-recognition-for-dummies-part-3.html" target="_blank">this tutorial</a> which has a nice explanation of the R-CNN family of detectors.</p>
<h2>Perspective Correction</h2>
<p>After detecting the bounding boxes, I could reliably locate a box for where the clock was located (even with other circles in the image). However, the clock’s shape was often distorted due to perspective changes. The later steps in the project rely on estimating the hand angles, so it was important for the clock to be a circle.</p>

    </div>
    <footer class="footer"><a href="https://jinay.dev">jinay.dev</a></footer>
</body>

</html>
